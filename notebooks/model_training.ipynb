{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139483db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Set\n",
    "from pathlib import Path # Added import\n",
    "\n",
    "def read_article(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read()\n",
    "    return raw.decode(\"utf-8\", \"ignore\")\n",
    "\n",
    "def load_span_labels(label_file: str\n",
    "    ) -> Dict[str, List[Tuple[str, int, int]]]:\n",
    "    \n",
    "    spans = defaultdict(list)\n",
    "    with open(label_file, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # Handle potential empty lines or lines with incorrect format\n",
    "            parts = line.rstrip().split(\"\\t\")\n",
    "            if len(parts) == 4:\n",
    "                art_id, lab, s, e = parts\n",
    "                try:\n",
    "                    spans[art_id].append((lab, int(s), int(e)))\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Skipping malformed line in {label_file}: {line.rstrip()}\")\n",
    "            elif line.strip(): # Print warning for non-empty, but malformed lines\n",
    "                 print(f\"Warning: Skipping malformed line in {label_file}: {line.rstrip()}\")\n",
    "    return spans\n",
    "\n",
    "# Added function to extract base classes from the span file\n",
    "def get_base_classes_from_spans(label_file: str) -> Set[str]:\n",
    "    base_classes = set()\n",
    "    with open(label_file, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip().split(\"\\t\")\n",
    "            if len(parts) == 4:\n",
    "                _, lab, _, _ = parts\n",
    "                base_classes.add(lab)\n",
    "            elif line.strip():\n",
    "                 # Warnings handled in load_span_labels, no need to repeat here\n",
    "                 pass\n",
    "    return base_classes\n",
    "\n",
    "def build_label_maps(\n",
    "    base_classes: set[str] # Changed input to accept a set of base classes\n",
    ") -> tuple[list[str], dict[str, int], dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    base_classes – A set containing all unique base label names (e.g., \"Appeal_to_Fear-Prejudice\")\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    bio_tags   – full list like [\"O\", \"B-Appeal_to_Fear-Prejudice\", \"I-Appeal_to_Fear-Prejudice\", …]\n",
    "    label2id   – {\"O\": 0, \"B-…\": 1, …}   – used to turn tags into numbers\n",
    "    id2label   – inverse of label2id      – needed by the model/Trainer\n",
    "    \"\"\"\n",
    "    # 1️⃣ Use the provided base classes\n",
    "    sorted_base_classes = sorted(list(base_classes))\n",
    "\n",
    "    # 2️⃣ build BIO strings\n",
    "    bio_tags = [\"O\"]                      # outside any span\n",
    "    for cls in sorted_base_classes:\n",
    "        bio_tags.extend([f\"B-{cls}\", f\"I-{cls}\"])   # beginning / inside\n",
    "\n",
    "    # 3️⃣ numeric maps\n",
    "    label2id = {tag: i for i, tag in enumerate(bio_tags)}\n",
    "    id2label = {i: tag for tag, i in label2id.items()}\n",
    "\n",
    "    return bio_tags, label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567f78d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 11853,    83,  3060,  7986,    47,    47,  1098, 20650,     5,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'offset_mapping': tensor([[[ 0,  0],\n",
      "         [ 0,  4],\n",
      "         [ 5,  7],\n",
      "         [ 8, 12],\n",
      "         [13, 17],\n",
      "         [18, 20],\n",
      "         [21, 23],\n",
      "         [23, 26],\n",
      "         [26, 29],\n",
      "         [29, 30],\n",
      "         [ 0,  0]]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizerFast\n",
    "\n",
    "# Load the pre-trained XLM-RoBERTa tokenizer\n",
    "# You can replace \"xlm-roberta-base\" with a specific model if needed\n",
    "tokenizer_name = \"xlm-roberta-base\"\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_text(text: str):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text using the pre-loaded XLMRobertaTokenizerFast.\n",
    "\n",
    "    Args:\n",
    "        text: The input string to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the tokenized 'input_ids', 'attention_mask', etc.\n",
    "    \"\"\"\n",
    "    # Tokenize the text, adding common options like truncation and max_length\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=512,  # You can adjust the max_length if needed\n",
    "        return_tensors=\"pt\", # Return PyTorch tensors, change to \"tf\" for TensorFlow if required\n",
    "        return_offsets_mapping=True, # Useful for aligning tokens with original text\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Example of how to use the function (optional)\n",
    "sample_text = \"Here is some text to tokenize.\"\n",
    "tokenized_result = tokenize_text(sample_text)\n",
    "print(tokenized_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad88d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['<s>', '▁Here', '▁is', '▁some', '▁text', '▁to', '▁to', 'ken', 'ize', '.', '</s>']\n",
      "Labels: ['O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-VERB', 'I-VERB', 'I-VERB', 'O', 'O']\n",
      "<s>             O               [0, 0]\n",
      "▁Here           O               [0, 4]\n",
      "▁is             O               [5, 7]\n",
      "▁some           B-LOC           [8, 12]\n",
      "▁text           O               [13, 17]\n",
      "▁to             O               [18, 20]\n",
      "▁to             B-VERB          [21, 23]\n",
      "ken             I-VERB          [23, 26]\n",
      "ize             I-VERB          [26, 29]\n",
      ".               O               [29, 30]\n",
      "</s>            O               [0, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "def align_labels_with_tokens(\n",
    "    tokenized_inputs: BatchEncoding,\n",
    "    spans: List[Tuple[str, int, int]]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Aligns character-level span labels with token-level BIO labels.\n",
    "    Handles cases where token spans partially overlap with label spans.\n",
    "\n",
    "    Args:\n",
    "        tokenized_inputs: Output from the tokenizer (must include 'offset_mapping').\n",
    "        spans: A list of tuples, where each tuple is (label, start_char, end_char).\n",
    "\n",
    "    Returns:\n",
    "        A list of BIO labels (e.g., \"O\", \"B-Label\", \"I-Label\") corresponding to each token.\n",
    "    \"\"\"\n",
    "    # Ensure offset mapping is present\n",
    "    if 'offset_mapping' not in tokenized_inputs:\n",
    "        raise ValueError(\"Tokenizer output must include 'offset_mapping'.\")\n",
    "\n",
    "    # offset_mapping is typically shape (batch_size, sequence_length, 2)\n",
    "    # Assuming batch_size is 1 for this function\n",
    "    # Removed .tolist() as the input might already be a list\n",
    "    offsets = tokenized_inputs['offset_mapping'][0]\n",
    "    num_tokens = len(offsets)\n",
    "    labels = [\"O\"] * num_tokens # Initialize all labels as Outside\n",
    "\n",
    "    # Sort spans by start index to handle potential overlaps consistently (optional but good practice)\n",
    "    # spans.sort(key=lambda x: x[1]) # Uncomment if sorting is desired\n",
    "\n",
    "    for label, start_char, end_char in spans:\n",
    "        found_first_token = False\n",
    "        for token_idx, (token_start, token_end) in enumerate(offsets):\n",
    "            # Skip special tokens (like [CLS], [SEP]) which have (0, 0) offset\n",
    "            if token_start == token_end:\n",
    "                continue\n",
    "\n",
    "            # Check for overlap between token span and label span\n",
    "            # This condition is true if there is *any* overlap, including partial overlaps.\n",
    "            # max(start1, start2) < min(end1, end2)\n",
    "            if max(token_start, start_char) < min(token_end, end_char):\n",
    "                # Assign B- tag to the first token overlapping the span\n",
    "                if not found_first_token:\n",
    "                    labels[token_idx] = f\"B-{label}\" # Begin label\n",
    "                    found_first_token = True\n",
    "                # Assign I- tag to subsequent tokens overlapping the *same* span\n",
    "                else:\n",
    "                    labels[token_idx] = f\"I-{label}\" # Inside label\n",
    "            # Optimization: If the token starts after the span ends,\n",
    "            # we don't need to check further for this span.\n",
    "            # elif token_start >= end_char:\n",
    "            #     break # Uncomment if spans are sorted by start_char\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Example Usage (using variables from previous cells if run in the same notebook)\n",
    "\n",
    "# Sample spans (replace with actual spans for your data)\n",
    "sample_spans = [\n",
    "    (\"LOC\", 8, 12),   # Corresponds to \"some\" in \"Here is some text to tokenize.\"\n",
    "    (\"VERB\", 21, 29) # Corresponds to \"tokenize\"\n",
    "]\n",
    "\n",
    "# Use the previously tokenized result\n",
    "aligned_labels = align_labels_with_tokens(tokenized_result, sample_spans)\n",
    "\n",
    "# Print tokens and their corresponding labels\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_result['input_ids'][0])\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Labels:\", aligned_labels)\n",
    "\n",
    "# Verify alignment (optional)\n",
    "for token, label, offset in zip(tokens, aligned_labels, tokenized_result['offset_mapping'][0].tolist()):\n",
    "    print(f\"{token:<15} {label:<15} {offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82494ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spans from: /home/twoface/persuasion-detection/data/processed/ru/train-labels-subtask-3-spans.txt\n",
      "Found spans for 190 articles.\n",
      "Extracting base classes...\n",
      "Found 23 unique base classes.\n",
      "Building label maps...\n",
      "Total BIO tags: 47\n",
      "Processing articles from: /home/twoface/persuasion-detection/data/processed/ru/unwrapped-articles\n",
      "Processing article 100/190 (ID: 2465)...\n",
      "Finished processing 190 articles.\n",
      "\n",
      "--- Sample Article ID: 24151 ---\n",
      "Tokenized Input Keys: dict_keys(['input_ids', 'attention_mask'])\n",
      "Number of Tokens: 459\n",
      "Number of Labels: 459\n",
      "Label2ID mapping (sample): [('O', 0), ('B-Appeal_to_Authority', 1), ('I-Appeal_to_Authority', 2), ('B-Appeal_to_Fear-Prejudice', 3), ('I-Appeal_to_Fear-Prejudice', 4)]\n"
     ]
    }
   ],
   "source": [
    "def create_token_label_mapping(\n",
    "    span_label_file: str,\n",
    "    article_dir: str,\n",
    "    tokenizer: XLMRobertaTokenizerFast,\n",
    "    max_length: int = 512\n",
    ") -> Tuple[Dict[str, BatchEncoding], Dict[str, List[int]], Dict[str, int], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Creates a mapping from article ID to tokenized inputs and numerical BIO labels.\n",
    "\n",
    "    Args:\n",
    "        span_label_file: Path to the file containing span labels (tsv format).\n",
    "        article_dir: Path to the directory containing the article text files.\n",
    "        tokenizer: An initialized Hugging Face tokenizer (e.g., XLMRobertaTokenizerFast).\n",
    "        max_length: Maximum sequence length for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - tokenized_articles: Dict mapping article_id to tokenized BatchEncoding.\n",
    "        - article_label_ids: Dict mapping article_id to list of numerical label IDs.\n",
    "        - label2id: Dictionary mapping BIO label strings to integer IDs.\n",
    "        - id2label: Dictionary mapping integer IDs to BIO label strings.\n",
    "    \"\"\"\n",
    "    print(f\"Loading spans from: {span_label_file}\")\n",
    "    spans_by_article = load_span_labels(span_label_file)\n",
    "    total_articles = len(spans_by_article)\n",
    "    print(f\"Found spans for {total_articles} articles.\")\n",
    "\n",
    "    print(\"Extracting base classes...\")\n",
    "    base_classes = get_base_classes_from_spans(span_label_file)\n",
    "    print(f\"Found {len(base_classes)} unique base classes.\")\n",
    "\n",
    "    print(\"Building label maps...\")\n",
    "    bio_tags, label2id, id2label = build_label_maps(base_classes)\n",
    "    print(f\"Total BIO tags: {len(bio_tags)}\")\n",
    "\n",
    "    tokenized_articles = {}\n",
    "    article_label_ids = {}\n",
    "    article_dir_path = Path(article_dir)\n",
    "\n",
    "    print(f\"Processing articles from: {article_dir}\")\n",
    "    processed_count = 0\n",
    "    for art_id, spans in spans_by_article.items():\n",
    "        processed_count += 1\n",
    "        if processed_count % 100 == 0: # Print progress every 100 articles\n",
    "             print(f\"Processing article {processed_count}/{total_articles} (ID: {art_id})...\")\n",
    "\n",
    "        article_path = article_dir_path / f\"article{art_id}.txt\"\n",
    "        if not article_path.exists():\n",
    "            print(f\"Warning: Article file not found, skipping: {article_path}\")\n",
    "            continue\n",
    "\n",
    "        text = read_article(str(article_path))\n",
    "\n",
    "        # Tokenize (using the function from the previous cell, adapting args)\n",
    "        tokenized_inputs = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_offsets_mapping=True,\n",
    "            # No return_tensors=\"pt\" here, keep as lists for now\n",
    "        )\n",
    "\n",
    "        # Align character spans to token BIO labels\n",
    "        # Need to wrap tokenized_inputs for align_labels_with_tokens\n",
    "        # It expects BatchEncoding, let's simulate batch size 1\n",
    "        temp_batch_encoding = BatchEncoding({\n",
    "            'input_ids': [tokenized_inputs['input_ids']],\n",
    "            'attention_mask': [tokenized_inputs['attention_mask']],\n",
    "            'offset_mapping': [tokenized_inputs['offset_mapping']]\n",
    "        })\n",
    "        bio_labels = align_labels_with_tokens(temp_batch_encoding, spans)\n",
    "\n",
    "        # Convert BIO labels to numerical IDs\n",
    "        label_ids = [label2id.get(label, label2id[\"O\"]) for label in bio_labels]\n",
    "\n",
    "        # Store results (remove offset mapping if not needed later)\n",
    "        tokenized_inputs.pop(\"offset_mapping\")\n",
    "        tokenized_articles[art_id] = tokenized_inputs\n",
    "        article_label_ids[art_id] = label_ids\n",
    "\n",
    "    print(f\"Finished processing {processed_count} articles.\")\n",
    "    return tokenized_articles, article_label_ids, label2id, id2label\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Define paths (adjust if necessary)\n",
    "span_file = \"/home/twoface/persuasion-detection/data/processed/ru/train-labels-subtask-3-spans.txt\"\n",
    "# Assuming articles are in a sibling 'articles/ru' directory relative to 'processed/ru'\n",
    "articles_path = \"/home/twoface/persuasion-detection/data/processed/ru/unwrapped-articles\" \n",
    "\n",
    "# Ensure the tokenizer is loaded (from the second cell)\n",
    "if 'tokenizer' not in locals():\n",
    "    print(\"Tokenizer not found, please run the tokenizer loading cell first.\")\n",
    "else:\n",
    "    # Call the function\n",
    "    tokenized_data, label_data, l2i, i2l = create_token_label_mapping(\n",
    "        span_file,\n",
    "        articles_path,\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "    # Display results for a sample article (if data was processed)\n",
    "    if tokenized_data:\n",
    "        sample_id = list(tokenized_data.keys())[0]\n",
    "        print(f\"\\n--- Sample Article ID: {sample_id} ---\")\n",
    "        print(\"Tokenized Input Keys:\", tokenized_data[sample_id].keys())\n",
    "        print(\"Number of Tokens:\", len(tokenized_data[sample_id]['input_ids']))\n",
    "        print(\"Number of Labels:\", len(label_data[sample_id]))\n",
    "        print(\"Label2ID mapping (sample):\", list(l2i.items())[:5])\n",
    "    else:\n",
    "        print(\"\\nNo articles were processed. Check paths and file existence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d13b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Hugging Face dataset...\n",
      "Preparing dataset from 190 articles...\n",
      "Finished preparing dataset. Total articles processed: 190. Skipped: 0.\n",
      "\n",
      "Dataset created successfully!\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 190\n",
      "})\n",
      "\n",
      "First example: {'input_ids': [0, 31420, 2582, 105, 29, 41883, 546, 407, 1739, 142317, 718, 190012, 1258, 49, 119065, 20, 75533, 29, 41883, 547, 407, 82847, 11519, 27546, 31420, 83420, 718, 190012, 1258, 75533, 29, 41883, 547, 407, 82847, 11519, 27546, 31420, 83420, 718, 190012, 1258, 77900, 65346, 1082, 29440, 14560, 1086, 183, 38088, 175436, 407, 23334, 97430, 44140, 16176, 190012, 292, 1097, 39061, 969, 54662, 53173, 49, 155980, 969, 54662, 103, 5999, 5, 5187, 79015, 111918, 75533, 4, 135, 24010, 62415, 130, 237748, 13022, 14560, 78568, 31420, 2582, 5, 4531, 214461, 4, 414, 4060, 22051, 5509, 13299, 86146, 197, 14560, 126750, 25514, 8808, 43123, 87781, 22480, 32187, 5, 94, 170196, 13299, 77, 23494, 3505, 86665, 70209, 146666, 5, 134739, 93142, 3318, 30236, 32578, 77, 100998, 4798, 35, 8044, 3795, 113360, 4, 3077, 81871, 73712, 130, 4, 136037, 53711, 16176, 190012, 1339, 292, 83694, 31420, 2582, 5, 672, 26512, 15126, 33330, 80649, 43155, 50406, 14560, 718, 1714, 54662, 59, 20151, 172271, 3925, 10041, 32578, 1739, 6, 53058, 96140, 148288, 105, 5, 79615, 49, 27193, 8165, 1266, 237748, 4988, 127523, 190012, 559, 518, 44140, 4, 3837, 61, 25390, 38088, 546, 3738, 424, 144718, 68146, 637, 811, 212, 736, 160461, 42534, 59, 27304, 21397, 31597, 1725, 10094, 5, 417, 85350, 103, 47720, 4, 211663, 216035, 419, 183, 16443, 205, 202950, 79170, 1266, 3693, 861, 1085, 173269, 3844, 61, 183, 48260, 68520, 751, 129, 30083, 17434, 105, 4988, 447, 23457, 677, 4, 92173, 59, 43705, 62008, 227, 91528, 19816, 1086, 190012, 1214, 1400, 7572, 13225, 19108, 380, 5, 417, 28804, 33862, 244, 31420, 2582, 237748, 4988, 2574, 4, 3077, 108201, 8534, 551, 1891, 34258, 73772, 103, 151480, 518, 1714, 5090, 26464, 77, 80734, 60769, 172271, 84, 44140, 85645, 21465, 3735, 36689, 5, 829, 3693, 2699, 255, 24840, 163376, 245, 29, 16122, 107043, 9, 114027, 59, 14560, 4, 49, 3295, 8165, 132498, 83694, 4, 414, 77, 75088, 1730, 94, 60957, 8807, 4, 819, 25077, 637, 3732, 1251, 94, 5216, 292, 159537, 31877, 1770, 12204, 4, 35, 518, 3925, 1097, 122090, 107339, 7867, 31224, 723, 135, 24819, 60128, 147186, 1114, 139343, 6, 104367, 2958, 35, 17880, 1196, 35201, 559, 135, 66778, 188448, 95076, 743, 1339, 292, 52207, 118210, 31420, 2582, 5, 49429, 49, 3640, 8165, 1266, 129, 1488, 24747, 8914, 187312, 60128, 4, 4222, 33846, 4401, 1739, 13022, 9694, 2262, 5347, 10698, 2233, 113062, 5, 5187, 111529, 197, 61040, 7082, 22418, 4, 13901, 1041, 32511, 6, 112887, 2097, 41268, 135, 190012, 1281, 49, 14560, 113389, 49, 2660, 4, 414, 13299, 109810, 65346, 4018, 4060, 4, 7176, 29, 51571, 68487, 38252, 419, 4, 7176, 49, 119065, 12868, 82417, 547, 61, 31497, 1874, 190012, 227, 4, 252, 34800, 105, 31877, 4988, 5308, 1770, 12204, 31420, 2582, 12504, 63111, 1730, 81871, 73712, 130, 135, 77, 80734, 60769, 27893, 1488, 58706, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 30, 30, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from typing import Dict, List\n",
    "from transformers.tokenization_utils_base import BatchEncoding # Already imported but good practice\n",
    "\n",
    "def create_hf_dataset(\n",
    "    tokenized_articles: Dict[str, Dict[str, List[int]]], # Adjusted type hint\n",
    "    article_label_ids: Dict[str, List[int]],\n",
    "    label2id: Dict[str, int] # Keep label2id for potential future use or validation\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    Creates a Hugging Face Dataset object from tokenized articles and labels.\n",
    "\n",
    "    Args:\n",
    "        tokenized_articles: Dict mapping article_id to tokenized inputs (Dict with 'input_ids', 'attention_mask').\n",
    "        article_label_ids: Dict mapping article_id to list of numerical label IDs.\n",
    "        label2id: Dictionary mapping BIO label strings to integer IDs (optional, could be used for validation).\n",
    "\n",
    "    Returns:\n",
    "        A Hugging Face Dataset object with columns 'input_ids', 'attention_mask', 'labels'.\n",
    "    \"\"\"\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(f\"Preparing dataset from {len(tokenized_articles)} articles...\")\n",
    "    skipped_count = 0\n",
    "    for art_id in tokenized_articles.keys():\n",
    "        if art_id not in article_label_ids:\n",
    "            print(f\"Warning: Labels not found for article {art_id}. Skipping.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        input_ids = tokenized_articles[art_id]['input_ids']\n",
    "        attention_mask = tokenized_articles[art_id]['attention_mask']\n",
    "        labels = article_label_ids[art_id]\n",
    "\n",
    "        # Sanity check: lengths must match\n",
    "        if not (len(input_ids) == len(attention_mask) == len(labels)):\n",
    "            print(f\"Warning: Length mismatch for article {art_id}. \",\n",
    "                  f\"input_ids: {len(input_ids)}, attention_mask: {len(attention_mask)}, labels: {len(labels)}. Skipping.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_attention_masks.append(attention_mask)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    print(f\"Finished preparing dataset. Total articles processed: {len(all_input_ids)}. Skipped: {skipped_count}.\")\n",
    "\n",
    "    if not all_input_ids: # Handle case where no data was processed\n",
    "        print(\"Error: No valid data found to create dataset.\")\n",
    "        return None\n",
    "\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attention_masks,\n",
    "        \"labels\": all_labels\n",
    "    }\n",
    "\n",
    "    # Create the Dataset object\n",
    "    hf_dataset = Dataset.from_dict(dataset_dict)\n",
    "    return hf_dataset\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Check if the required variables exist from the previous cell\n",
    "if 'tokenized_data' in locals() and 'label_data' in locals() and 'l2i' in locals():\n",
    "    print(\"\\nCreating Hugging Face dataset...\")\n",
    "    # Ensure the data is not empty before proceeding\n",
    "    if tokenized_data and label_data:\n",
    "        train_dataset = create_hf_dataset(tokenized_data, label_data, l2i)\n",
    "\n",
    "        if train_dataset:\n",
    "            print(\"\\nDataset created successfully!\")\n",
    "            print(train_dataset)\n",
    "            # You can inspect the first example:\n",
    "            print(\"\\nFirst example:\", train_dataset[0])\n",
    "        else:\n",
    "            print(\"\\nDataset creation failed.\")\n",
    "    else:\n",
    "        print(\"\\nCannot create dataset: 'tokenized_data' or 'label_data' is empty.\")\n",
    "else:\n",
    "    print(\"\\nPlease run the previous cells to generate 'tokenized_data', 'label_data', and 'l2i'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4e1d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting the first example (train_dataset[0]) ---\n",
      "{'input_ids': [0, 31420, 2582, 105, 29, 41883, 546, 407, 1739, 142317, 718, 190012, 1258, 49, 119065, 20, 75533, 29, 41883, 547, 407, 82847, 11519, 27546, 31420, 83420, 718, 190012, 1258, 75533, 29, 41883, 547, 407, 82847, 11519, 27546, 31420, 83420, 718, 190012, 1258, 77900, 65346, 1082, 29440, 14560, 1086, 183, 38088, 175436, 407, 23334, 97430, 44140, 16176, 190012, 292, 1097, 39061, 969, 54662, 53173, 49, 155980, 969, 54662, 103, 5999, 5, 5187, 79015, 111918, 75533, 4, 135, 24010, 62415, 130, 237748, 13022, 14560, 78568, 31420, 2582, 5, 4531, 214461, 4, 414, 4060, 22051, 5509, 13299, 86146, 197, 14560, 126750, 25514, 8808, 43123, 87781, 22480, 32187, 5, 94, 170196, 13299, 77, 23494, 3505, 86665, 70209, 146666, 5, 134739, 93142, 3318, 30236, 32578, 77, 100998, 4798, 35, 8044, 3795, 113360, 4, 3077, 81871, 73712, 130, 4, 136037, 53711, 16176, 190012, 1339, 292, 83694, 31420, 2582, 5, 672, 26512, 15126, 33330, 80649, 43155, 50406, 14560, 718, 1714, 54662, 59, 20151, 172271, 3925, 10041, 32578, 1739, 6, 53058, 96140, 148288, 105, 5, 79615, 49, 27193, 8165, 1266, 237748, 4988, 127523, 190012, 559, 518, 44140, 4, 3837, 61, 25390, 38088, 546, 3738, 424, 144718, 68146, 637, 811, 212, 736, 160461, 42534, 59, 27304, 21397, 31597, 1725, 10094, 5, 417, 85350, 103, 47720, 4, 211663, 216035, 419, 183, 16443, 205, 202950, 79170, 1266, 3693, 861, 1085, 173269, 3844, 61, 183, 48260, 68520, 751, 129, 30083, 17434, 105, 4988, 447, 23457, 677, 4, 92173, 59, 43705, 62008, 227, 91528, 19816, 1086, 190012, 1214, 1400, 7572, 13225, 19108, 380, 5, 417, 28804, 33862, 244, 31420, 2582, 237748, 4988, 2574, 4, 3077, 108201, 8534, 551, 1891, 34258, 73772, 103, 151480, 518, 1714, 5090, 26464, 77, 80734, 60769, 172271, 84, 44140, 85645, 21465, 3735, 36689, 5, 829, 3693, 2699, 255, 24840, 163376, 245, 29, 16122, 107043, 9, 114027, 59, 14560, 4, 49, 3295, 8165, 132498, 83694, 4, 414, 77, 75088, 1730, 94, 60957, 8807, 4, 819, 25077, 637, 3732, 1251, 94, 5216, 292, 159537, 31877, 1770, 12204, 4, 35, 518, 3925, 1097, 122090, 107339, 7867, 31224, 723, 135, 24819, 60128, 147186, 1114, 139343, 6, 104367, 2958, 35, 17880, 1196, 35201, 559, 135, 66778, 188448, 95076, 743, 1339, 292, 52207, 118210, 31420, 2582, 5, 49429, 49, 3640, 8165, 1266, 129, 1488, 24747, 8914, 187312, 60128, 4, 4222, 33846, 4401, 1739, 13022, 9694, 2262, 5347, 10698, 2233, 113062, 5, 5187, 111529, 197, 61040, 7082, 22418, 4, 13901, 1041, 32511, 6, 112887, 2097, 41268, 135, 190012, 1281, 49, 14560, 113389, 49, 2660, 4, 414, 13299, 109810, 65346, 4018, 4060, 4, 7176, 29, 51571, 68487, 38252, 419, 4, 7176, 49, 119065, 12868, 82417, 547, 61, 31497, 1874, 190012, 227, 4, 252, 34800, 105, 31877, 4988, 5308, 1770, 12204, 31420, 2582, 12504, 63111, 1730, 81871, 73712, 130, 135, 77, 80734, 60769, 27893, 1488, 58706, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 30, 30, 30, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0]}\n",
      "\n",
      "Number of tokens: 459\n",
      "Number of labels: 459\n",
      "Number of attention mask values: 459\n",
      "\n",
      "--- Inspecting the first 3 examples (train_dataset[:3]) ---\n",
      "Keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "Number of examples in slice: 3\n"
     ]
    }
   ],
   "source": [
    "# Inspect the created dataset\n",
    "\n",
    "if 'train_dataset' in locals() and train_dataset is not None and len(train_dataset) > 0:\n",
    "    print(\"--- Inspecting the first example (train_dataset[0]) ---\")\n",
    "    first_example = train_dataset[0]\n",
    "    print(first_example)\n",
    "    print(\"\\nNumber of tokens:\", len(first_example['input_ids']))\n",
    "    print(\"Number of labels:\", len(first_example['labels']))\n",
    "    print(\"Number of attention mask values:\", len(first_example['attention_mask']))\n",
    "\n",
    "    print(\"\\n--- Inspecting the first 3 examples (train_dataset[:3]) ---\")\n",
    "    # Slicing returns a dictionary where each key maps to a list of values for that slice\n",
    "    first_three_examples = train_dataset[:3]\n",
    "    # Print lengths to show structure\n",
    "    print(\"Keys:\", first_three_examples.keys())\n",
    "    print(\"Number of examples in slice:\", len(first_three_examples['input_ids'])) # Should be 3\n",
    "    # Optionally print the details of the first example within the slice\n",
    "    # print(\"\\nDetails of first example in slice:\")\n",
    "    # print({\"input_ids\": first_three_examples['input_ids'][0], \n",
    "    #        \"attention_mask\": first_three_examples['attention_mask'][0], \n",
    "    #        \"labels\": first_three_examples['labels'][0]})\n",
    "elif 'train_dataset' in locals() and train_dataset is not None:\n",
    "     print(\"The train_dataset is empty.\")\n",
    "else:\n",
    "    print(\"Variable 'train_dataset' not found or is None. Please run the previous cell to create it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a55794",
   "metadata": {},
   "source": [
    "## Model Training Setup\n",
    "\n",
    "Now we set up the components needed for training:\n",
    "1.  **Load Model**: Load `XLMRobertaForTokenClassification` with the correct number of labels.\n",
    "2.  **Training Arguments**: Configure hyperparameters like learning rate, batch size, epochs, and output directories.\n",
    "3.  **Metrics**: Define a function to compute evaluation metrics (precision, recall, F1) using `seqeval`.\n",
    "4.  **Data Collator**: Use `DataCollatorForTokenClassification` for dynamic padding.\n",
    "5.  **Trainer**: Initialize the `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc44c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 190\n",
      "Train split size: 171\n",
      "Evaluation split size: 19\n",
      "\n",
      "Train split structure:\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 171\n",
      "})\n",
      "\n",
      "Evaluation split structure:\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 19\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset (e.g., 90% train, 10% evaluation)\n",
    "# Use shuffle=True (default) and a seed for reproducibility\n",
    "split_dataset = train_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Assign the splits to new variables\n",
    "train_split = split_dataset['train']\n",
    "eval_split = split_dataset['test'] # The 'test' key holds the evaluation split\n",
    "\n",
    "print(f\"Original dataset size: {len(train_dataset)}\")\n",
    "print(f\"Train split size: {len(train_split)}\")\n",
    "print(f\"Evaluation split size: {len(eval_split)}\")\n",
    "\n",
    "# Display the structure of the splits\n",
    "print(\"\\nTrain split structure:\")\n",
    "print(train_split)\n",
    "print(\"\\nEvaluation split structure:\")\n",
    "print(eval_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d8461bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: xlm-roberta-base with 47 labels.\n",
      "TrainingArguments defined.\n",
      "compute_metrics function defined.\n",
      "DataCollatorForTokenClassification initialized.\n",
      "compute_metrics function defined.\n",
      "DataCollatorForTokenClassification initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62112/4072117509.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "import evaluate # Use evaluate instead of load_metric\n",
    "\n",
    "print(\"Setting up training components...\")\n",
    "# 1. Load Model\n",
    "model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    tokenizer_name,\n",
    "    id2label=i2l,\n",
    "    label2id=l2i\n",
    ")\n",
    "print(f\"Model loaded: {tokenizer_name} with {model.config.num_labels} labels.\")\n",
    "\n",
    "# 2. Training Arguments\n",
    "# Note: Adjust these arguments based on your resources and needs\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\", # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    # Add save_strategy if you want to save checkpoints\n",
    "    # load_best_model_at_end=True, # Requires save_strategy and evaluation_strategy\n",
    ")\n",
    "print(\"TrainingArguments defined.\")\n",
    "\n",
    "# 3. Metrics Calculation\n",
    "metric = evaluate.load(\"seqeval\") # Use evaluate.load\n",
    "# Get the actual label names (without B-/I- prefixes for seqeval)\n",
    "# Assuming i2l contains labels like 'O', 'B-Label1', 'I-Label1', ...\n",
    "label_list = list(i2l.values())\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens) - where label is -100\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "print(\"compute_metrics function defined.\")\n",
    "\n",
    "# 4. Data Collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "print(\"DataCollatorForTokenClassification initialized.\")\n",
    "\n",
    "# 5. Trainer\n",
    "# Assuming train_dataset is your training data.\n",
    "# If you have a separate validation set, add it as `eval_dataset`\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_split,\n",
    "    eval_dataset=eval_split, # Using train_dataset for evaluation here, replace if you have a validation set\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"Trainer initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b909c91",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "Execute the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d33791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 01:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.149500</td>\n",
       "      <td>2.121316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.938100</td>\n",
       "      <td>1.862920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.683900</td>\n",
       "      <td>1.819779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/twoface/persuasion-detection/.venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training finished.\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               =   124890GF\n",
      "  train_loss               =     2.2091\n",
      "  train_runtime            = 0:01:11.86\n",
      "  train_samples_per_second =      7.138\n",
      "  train_steps_per_second   =      0.459\n"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "if 'trainer' in locals() and trainer is not None:\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_result = trainer.train()\n",
    "    print(\"\\nTraining finished.\")\n",
    "\n",
    "    # Optionally, save the final model, tokenizer, and training arguments\n",
    "    # trainer.save_model(\"./final_model\") \n",
    "    # print(\"Model saved to ./final_model\")\n",
    "\n",
    "    # Log metrics\n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "else:\n",
    "    print(\"\\nTrainer was not initialized. Cannot start training. Please check the setup cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
